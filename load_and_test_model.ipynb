{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":245009709,"sourceType":"kernelVersion"},{"sourceId":245064960,"sourceType":"kernelVersion"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install arabert","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T20:05:15.999374Z","iopub.execute_input":"2025-06-12T20:05:15.999665Z","iopub.status.idle":"2025-06-12T20:05:24.505963Z","shell.execute_reply.started":"2025-06-12T20:05:15.999641Z","shell.execute_reply":"2025-06-12T20:05:24.504928Z"}},"outputs":[{"name":"stdout","text":"Collecting arabert\n  Downloading arabert-1.0.1-py3-none-any.whl.metadata (16 kB)\nRequirement already satisfied: PyArabic in /usr/local/lib/python3.11/dist-packages (from arabert) (0.6.15)\nCollecting farasapy (from arabert)\n  Downloading farasapy-0.0.14-py3-none-any.whl.metadata (8.9 kB)\nCollecting emoji==1.4.2 (from arabert)\n  Downloading emoji-1.4.2.tar.gz (184 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from farasapy->arabert) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from farasapy->arabert) (4.67.1)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from PyArabic->arabert) (1.17.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy->arabert) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy->arabert) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy->arabert) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->farasapy->arabert) (2025.4.26)\nDownloading arabert-1.0.1-py3-none-any.whl (179 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading farasapy-0.0.14-py3-none-any.whl (11 kB)\nBuilding wheels for collected packages: emoji\n  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186456 sha256=20cc4901e9bea279407c34e397173c45d73126269b17667f1d2e77c8fb3f1b42\n  Stored in directory: /root/.cache/pip/wheels/94/08/b4/78657b1541bb704b088317b52429ee4016d9888fe47dbb130f\nSuccessfully built emoji\nInstalling collected packages: emoji, farasapy, arabert\n  Attempting uninstall: emoji\n    Found existing installation: emoji 2.14.1\n    Uninstalling emoji-2.14.1:\n      Successfully uninstalled emoji-2.14.1\nSuccessfully installed arabert-1.0.1 emoji-1.4.2 farasapy-0.0.14\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport numpy as np\nimport tensorflow as tf\nfrom transformers import AutoTokenizer, AutoConfig, TFAutoModelForSequenceClassification\nfrom arabert.preprocess import ArabertPreprocessor\nfrom sklearn.preprocessing import LabelEncoder\n\nclass ArabicSentimentClassifier:\n    def __init__(self, model_path, model_name=\"aubmindlab/bert-base-arabertv2\"):\n        print(\"Initializing Arabic Sentiment Classifier...\")\n\n        self.arabert_prep = ArabertPreprocessor(model_name=model_name)\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n        # Load the model\n        try:\n            config = AutoConfig.from_pretrained(os.path.join(model_path, 'config.json'))\n            print(\"Config loaded successfully.\")\n\n            self.model = TFAutoModelForSequenceClassification.from_pretrained(\n                model_path, config=config, from_tf=True\n            )\n            print(\"Model loaded from directory using config and .h5!\")\n        except Exception as e:\n            print(f\"Error loading from directory: {e}\")\n            print(\"Attempting fallback loading with model_name and weights...\")\n            self.model = TFAutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n\n            # Manually load weights\n            h5_file = next((f for f in os.listdir(model_path) if f.endswith(\".h5\")), None)\n            if not h5_file:\n                raise ValueError(\"No .h5 file found in the provided directory.\")\n            self.model.load_weights(os.path.join(model_path, h5_file))\n            print(\"Model weights loaded successfully.\")\n\n        # Setup label encoder\n        self.label_encoder = LabelEncoder()\n        self.label_encoder.fit(['0','1', '2'])\n\n    def classify_text(self, text):\n        processed_text = self.arabert_prep.preprocess(text)\n        encoding = self.tokenizer(\n            processed_text,\n            truncation=True,\n            padding='max_length',\n            max_length=512,\n            return_tensors='tf'\n        )\n\n        output = self.model(encoding)\n        probabilities = tf.nn.softmax(output.logits, axis=-1).numpy()[0]\n        predicted_idx = np.argmax(probabilities)\n        predicted_label = self.label_encoder.classes_[predicted_idx]\n        confidence = probabilities[predicted_idx]\n\n        return {\n            \"original_text\": text,\n            \"processed_text\": processed_text,\n            \"predicted_class\": predicted_label,\n            \"confidence\": float(confidence),\n            \"all_probabilities\": {\n                label: float(prob) for label, prob in zip(self.label_encoder.classes_, probabilities)\n            }\n        }\n\n    def classify_batch(self, texts):\n        return [self.classify_text(text) for text in texts]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T20:05:24.507980Z","iopub.execute_input":"2025-06-12T20:05:24.508282Z","iopub.status.idle":"2025-06-12T20:05:57.695063Z","shell.execute_reply.started":"2025-06-12T20:05:24.508253Z","shell.execute_reply":"2025-06-12T20:05:57.693981Z"}},"outputs":[{"name":"stderr","text":"2025-06-12 20:05:26.919856: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749758727.188835      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749758727.267062      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"\nMODEL_PATH = \"/kaggle/input/fork-of-sentiment-analysis-of-messages/arabic_sentiment_model/\"  \n\nclassifier = ArabicSentimentClassifier(MODEL_PATH)\n\nexamples = [\n    \"هذه الشركة ممتازة وأنصح بالعمل بها\",\n    \"الإدارة سيئة جداً والراتب قليل\",\n    \"الشركة عادية، لا بأس بها\",\n    \"أحب العمل هنا كثيراً\",\n    \"التجربة مخيبة للآمال\"\n]\n\nfor i, text in enumerate(examples, 1):\n    result = classifier.classify_text(text)\n    print(f\"\\nExample {i}: {text}\")\n    print(f\"  Predicted Class: {result['predicted_class']}\")\n    print(f\"  Confidence: {result['confidence']:.2f}\")\n    for cls, prob in result['all_probabilities'].items():\n        print(f\"    {cls}: {prob:.4f}\")\n\n# Quick function (optional)\ndef quick_classify(text, model_path):\n    return ArabicSentimentClassifier(model_path).classify_text(text)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-12T20:05:57.695933Z","iopub.execute_input":"2025-06-12T20:05:57.696493Z","iopub.status.idle":"2025-06-12T20:12:30.994563Z","shell.execute_reply.started":"2025-06-12T20:05:57.696470Z","shell.execute_reply":"2025-06-12T20:12:30.993525Z"}},"outputs":[{"name":"stdout","text":"Initializing Arabic Sentiment Classifier...\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'farasa-api.qcri.org'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"100%|██████████| 241M/241M [05:59<00:00, 671kiB/s] \n","output_type":"stream"},{"name":"stderr","text":"[2025-06-12 20:11:59,111 - farasapy_logger - WARNING]: Be careful with large lines as they may break on interactive mode. You may switch to Standalone mode for such cases.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/611 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a13367d1031d4b339fa0e065a1fa169c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/384 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8bc7b9462ce64edea83e54f55df4e2f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/720k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1eb11eb23f14c679071018ca943078b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"41ef35b590d3432d8d902e9feda4353f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd31b78e2e0b43779840852ff7b2932c"}},"metadata":{}},{"name":"stdout","text":"Config loaded successfully.\nError loading from directory: ('Keyword argument not understood:', 'from_tf')\nAttempting fallback loading with model_name and weights...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/543M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a0fc34b124348d3bab815b36f982790"}},"metadata":{}},{"name":"stderr","text":"2025-06-12 20:12:16.719916: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\nSome weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Model weights loaded successfully.\n\nExample 1: هذه الشركة ممتازة وأنصح بالعمل بها\n  Predicted Class: 2\n  Confidence: 0.99\n    0: 0.0051\n    1: 0.0065\n    2: 0.9884\n\nExample 2: الإدارة سيئة جداً والراتب قليل\n  Predicted Class: 0\n  Confidence: 0.99\n    0: 0.9866\n    1: 0.0035\n    2: 0.0100\n\nExample 3: الشركة عادية، لا بأس بها\n  Predicted Class: 2\n  Confidence: 0.52\n    0: 0.0836\n    1: 0.3916\n    2: 0.5248\n\nExample 4: أحب العمل هنا كثيراً\n  Predicted Class: 2\n  Confidence: 0.99\n    0: 0.0060\n    1: 0.0066\n    2: 0.9874\n\nExample 5: التجربة مخيبة للآمال\n  Predicted Class: 0\n  Confidence: 0.95\n    0: 0.9494\n    1: 0.0122\n    2: 0.0384\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"negative_sentences = [\n    \"صارلي أسبوع بستنى وما حدا رد عليّ.\",\n    \"أنا دافع كل المستحقات ولسّا الحساب محجوز!\",\n    \"ليش كل مرة بدي أراجع الفرع عشان أحل المشكلة؟\",\n    \"ما في حدا فاهمني أو بيعطيني جواب واضح!\",\n    \"كل شوي بتغيروا الحكي، وأنا تعبت!\",\n    \"هاد مش أول مرة يصير معي هيك، عنجد الوضع صار مزعج!\",\n    \"ليش تأخرتوا بتحويل الراتب؟ هيك بتخربولي التزاماتي!\",\n    \"من الصبح بتصل وما في رد، هاد اسمه بنك؟\",\n    \"كل ما أراجع بقولولي 'راجع بعدين'، وأنا ما عندي وقت!\",\n    \"حسّيت إني بضيع وقتي وولا شي انحل!\",\n    \"قرف يقرفكم\"\n]\nclassifier.classify_batch(negative_sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T20:12:30.996815Z","iopub.execute_input":"2025-06-12T20:12:30.997164Z","iopub.status.idle":"2025-06-12T20:12:46.227116Z","shell.execute_reply.started":"2025-06-12T20:12:30.997132Z","shell.execute_reply":"2025-06-12T20:12:46.226073Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"[{'original_text': 'صارلي أسبوع بستنى وما حدا رد عليّ.',\n  'processed_text': 'صارلي أسبوع ب+ ستنى و+ ما حد +ا رد علي .',\n  'predicted_class': '0',\n  'confidence': 0.6818404197692871,\n  'all_probabilities': {'0': 0.6818404197692871,\n   '1': 0.06753765046596527,\n   '2': 0.2506219446659088}},\n {'original_text': 'أنا دافع كل المستحقات ولسّا الحساب محجوز!',\n  'processed_text': 'أنا دافع كل ال+ مستحق +ات ولس +ا ال+ حساب محجوز !',\n  'predicted_class': '0',\n  'confidence': 0.8504119515419006,\n  'all_probabilities': {'0': 0.8504119515419006,\n   '1': 0.04518069699406624,\n   '2': 0.10440736263990402}},\n {'original_text': 'ليش كل مرة بدي أراجع الفرع عشان أحل المشكلة؟',\n  'processed_text': 'ل+ يش كل مر +ة بدي أراجع ال+ فرع عشان أحل ال+ مشكل +ة ؟',\n  'predicted_class': '0',\n  'confidence': 0.7454066872596741,\n  'all_probabilities': {'0': 0.7454066872596741,\n   '1': 0.11967132240533829,\n   '2': 0.13492195308208466}},\n {'original_text': 'ما في حدا فاهمني أو بيعطيني جواب واضح!',\n  'processed_text': 'ما في حد +ا فاهمني أو بيعطيني جواب واضح !',\n  'predicted_class': '0',\n  'confidence': 0.8713027834892273,\n  'all_probabilities': {'0': 0.8713027834892273,\n   '1': 0.031110556796193123,\n   '2': 0.09758658707141876}},\n {'original_text': 'كل شوي بتغيروا الحكي، وأنا تعبت!',\n  'processed_text': 'كل شوي ب+ تغيروا ال+ حكي ، و+ أنا تعب +ت !',\n  'predicted_class': '0',\n  'confidence': 0.9651618599891663,\n  'all_probabilities': {'0': 0.9651618599891663,\n   '1': 0.01627418026328087,\n   '2': 0.018563944846391678}},\n {'original_text': 'هاد مش أول مرة يصير معي هيك، عنجد الوضع صار مزعج!',\n  'processed_text': 'هاد مش أول مر +ة يصير مع +ي هي +ك ، عنجد ال+ وضع صار مزعج !',\n  'predicted_class': '0',\n  'confidence': 0.9298170804977417,\n  'all_probabilities': {'0': 0.9298170804977417,\n   '1': 0.027166705578565598,\n   '2': 0.04301626607775688}},\n {'original_text': 'ليش تأخرتوا بتحويل الراتب؟ هيك بتخربولي التزاماتي!',\n  'processed_text': 'ل+ يش تأخرت +وا ب+ تحويل ال+ راتب ؟ هي +ك بتخربولي التزام +ات +ي !',\n  'predicted_class': '0',\n  'confidence': 0.9325849413871765,\n  'all_probabilities': {'0': 0.9325849413871765,\n   '1': 0.03132254257798195,\n   '2': 0.03609257563948631}},\n {'original_text': 'من الصبح بتصل وما في رد، هاد اسمه بنك؟',\n  'processed_text': 'من ال+ صبح ب+ تصل و+ ما في رد ، هاد اسم +ه بنك ؟',\n  'predicted_class': '0',\n  'confidence': 0.9321560859680176,\n  'all_probabilities': {'0': 0.9321560859680176,\n   '1': 0.020849555730819702,\n   '2': 0.046994298696517944}},\n {'original_text': \"كل ما أراجع بقولولي 'راجع بعدين'، وأنا ما عندي وقت!\",\n  'processed_text': \"كل ما أراجع ب+ قولولي ' راجع بعد +ين ' ، و+ أنا ما عند +ي وقت !\",\n  'predicted_class': '0',\n  'confidence': 0.8803012371063232,\n  'all_probabilities': {'0': 0.8803012371063232,\n   '1': 0.029916441068053246,\n   '2': 0.08978234976530075}},\n {'original_text': 'حسّيت إني بضيع وقتي وولا شي انحل!',\n  'processed_text': 'حسي +ت إن +ي ب+ ضيع وقتي وول +ا شي انحل !',\n  'predicted_class': '0',\n  'confidence': 0.8393596410751343,\n  'all_probabilities': {'0': 0.8393596410751343,\n   '1': 0.01979866996407509,\n   '2': 0.14084172248840332}},\n {'original_text': 'قرف يقرفكم',\n  'processed_text': 'قرف يقرفكم',\n  'predicted_class': '0',\n  'confidence': 0.9728190302848816,\n  'all_probabilities': {'0': 0.9728190302848816,\n   '1': 0.0037333897780627012,\n   '2': 0.023447496816515923}}]"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"positive_sentences = [\n    \"عنجد شكراً، خدمتكم ممتازة اليوم.\",\n    \"كل الاحترام لإلك، ساعدتيني كتير.\",\n    \"هي أول مرة بتعامل معكم، والتجربة كانت ممتازة.\",\n    \"بصراحة، كتير مبسوط من سرعة الرد والمتابعة.\",\n    \"بشكر البنك على اهتمامه بحل المشكلة بسرعة.\",\n    \"أنا زبون عندكم من زمان، وما عمري شفت تقصير.\",\n    \"ما قصّرتوا معي، يعطيكم العافية.\",\n    \"واضح إنو في تحسن كبير بخدمتكم، استمروا هيك.\",\n    \"شكراً لإنك وضحتلي الموضوع بكل سهولة.\",\n    \"دايمًا بلاقي حد يساعدني وقت الحاجة، شكراً إلكم.\"\n]\nclassifier.classify_batch(positive_sentences)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T20:12:46.228060Z","iopub.execute_input":"2025-06-12T20:12:46.228350Z","iopub.status.idle":"2025-06-12T20:12:59.478756Z","shell.execute_reply.started":"2025-06-12T20:12:46.228320Z","shell.execute_reply":"2025-06-12T20:12:59.477922Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"[{'original_text': 'عنجد شكراً، خدمتكم ممتازة اليوم.',\n  'processed_text': 'عنجد شكر +ا ، خدم +ت +كم ممتاز +ة ال+ يوم .',\n  'predicted_class': '2',\n  'confidence': 0.9887514710426331,\n  'all_probabilities': {'0': 0.005748237948864698,\n   '1': 0.005500297527760267,\n   '2': 0.9887514710426331}},\n {'original_text': 'كل الاحترام لإلك، ساعدتيني كتير.',\n  'processed_text': 'كل ال+ احترام ل+ إلك ، ساعدتيني كتير .',\n  'predicted_class': '2',\n  'confidence': 0.9864968657493591,\n  'all_probabilities': {'0': 0.006995543371886015,\n   '1': 0.006507613696157932,\n   '2': 0.9864968657493591}},\n {'original_text': 'هي أول مرة بتعامل معكم، والتجربة كانت ممتازة.',\n  'processed_text': 'هي أول مر +ة ب+ تعامل مع +كم ، و+ ال+ تجرب +ة كان +ت ممتاز +ة .',\n  'predicted_class': '2',\n  'confidence': 0.981604814529419,\n  'all_probabilities': {'0': 0.008054552599787712,\n   '1': 0.010340603068470955,\n   '2': 0.981604814529419}},\n {'original_text': 'بصراحة، كتير مبسوط من سرعة الرد والمتابعة.',\n  'processed_text': 'ب+ صراح +ة ، كتير مبسوط من سرع +ة ال+ رد و+ ال+ متابع +ة .',\n  'predicted_class': '2',\n  'confidence': 0.9867392778396606,\n  'all_probabilities': {'0': 0.00610482320189476,\n   '1': 0.0071558780036866665,\n   '2': 0.9867392778396606}},\n {'original_text': 'بشكر البنك على اهتمامه بحل المشكلة بسرعة.',\n  'processed_text': 'ب+ شكر ال+ بنك على اهتمام +ه ب+ حل ال+ مشكل +ة ب+ سرع +ة .',\n  'predicted_class': '2',\n  'confidence': 0.9491414427757263,\n  'all_probabilities': {'0': 0.024011526256799698,\n   '1': 0.02684696950018406,\n   '2': 0.9491414427757263}},\n {'original_text': 'أنا زبون عندكم من زمان، وما عمري شفت تقصير.',\n  'processed_text': 'أنا زبون عند +كم من زمان ، و+ ما عمري شفت تقصير .',\n  'predicted_class': '0',\n  'confidence': 0.6352344155311584,\n  'all_probabilities': {'0': 0.6352344155311584,\n   '1': 0.09445630013942719,\n   '2': 0.2703092396259308}},\n {'original_text': 'ما قصّرتوا معي، يعطيكم العافية.',\n  'processed_text': 'ما قصرت +وا مع +ي ، يعطيكم ال+ عافي +ة .',\n  'predicted_class': '2',\n  'confidence': 0.9864565134048462,\n  'all_probabilities': {'0': 0.006845601834356785,\n   '1': 0.00669785775244236,\n   '2': 0.9864565134048462}},\n {'original_text': 'واضح إنو في تحسن كبير بخدمتكم، استمروا هيك.',\n  'processed_text': 'واضح إنو في تحسن كبير بخدمتكم ، استمر +وا هي +ك .',\n  'predicted_class': '2',\n  'confidence': 0.8081775307655334,\n  'all_probabilities': {'0': 0.0568791888654232,\n   '1': 0.13494330644607544,\n   '2': 0.8081775307655334}},\n {'original_text': 'شكراً لإنك وضحتلي الموضوع بكل سهولة.',\n  'processed_text': 'شكر +ا ل+ إن +ك و+ ضحتلي ال+ موضوع ب+ كل سهول +ة .',\n  'predicted_class': '2',\n  'confidence': 0.9872393012046814,\n  'all_probabilities': {'0': 0.005468669813126326,\n   '1': 0.0072919768281280994,\n   '2': 0.9872393012046814}},\n {'original_text': 'دايمًا بلاقي حد يساعدني وقت الحاجة، شكراً إلكم.',\n  'processed_text': 'دائم +ا ب+ لاقي حد يساعدني وقت ال+ حاج +ة ، شكر +ا إلكم .',\n  'predicted_class': '2',\n  'confidence': 0.9722456336021423,\n  'all_probabilities': {'0': 0.018356315791606903,\n   '1': 0.009398054331541061,\n   '2': 0.9722456336021423}}]"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"import time \n\n\nstart_time = time.time()\nneutral_sentences = [\n    \"بدي أستفسر عن الرصيد بحسابي.\"\n \n]\n\nclassifier.classify_batch(neutral_sentences)\n\nend_time = time.time()\n\nprint(end_time-start_time)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T20:14:19.019346Z","iopub.execute_input":"2025-06-12T20:14:19.019682Z","iopub.status.idle":"2025-06-12T20:14:20.334829Z","shell.execute_reply.started":"2025-06-12T20:14:19.019651Z","shell.execute_reply":"2025-06-12T20:14:20.333964Z"}},"outputs":[{"name":"stdout","text":"1.3104887008666992\n","output_type":"stream"}],"execution_count":8}]}